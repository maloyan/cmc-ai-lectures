{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2adee08d-4354-4a39-9e44-1b5893bf52c0",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1904.08994.pdf\n",
    "\n",
    "### GANs\n",
    "\n",
    "**Генеративно-состязательные сети (GANs)** продемонстрировали значительные успехи в широком спектре задач генерации, успешно моделируя сложные аспекты реального мира, такие как изображения, аудио и др.. Концепция GANs, находящая вдохновение в теории игр, предполагает взаимодействие двух отдельных элементов: генератора и дискриминатора (или критика). Эти компоненты находятся в состоянии соперничества, при этом каждый из них стремится улучшить свои функциональные возможности, одновременно способствуя улучшению противоположной стороны. Тем не менее, процесс обучения GANs сопряжен с рядом сложностей, в особенности связанных с нестабильностью и трудностями достижения сходимости.\n",
    "\n",
    "### Дивергенция Кульбака-Лейблера и Дженсена-Шеннона\n",
    "\n",
    "Прежде чем подробно рассмотреть генеративно-состязательные сети (GAN), давайте рассмотрим две метрики для количественной оценки сходства между двумя вероятностными распределениями.\n",
    "\n",
    "1. **Дивергенция Кульбака-Лейблера (KL-дивергенция)** измеряет, насколько одно вероятностное распределение $ p $ отличается от другого ожидаемого вероятностного распределения $ q $. Математически это выражается формулой:\n",
    "\n",
    "   $$ D_{KL}(p \\parallel q) = \\int_x p(x) \\log \\frac{p(x)}{q(x)} dx $$\n",
    "\n",
    "   $ D_{KL} $ достигает минимума, равного нулю, когда $ p(x) $ идентично $ q(x) $ везде.\n",
    "\n",
    "   Отметим, что формула показывает, что KL-дивергенция асимметрична. В случаях, когда $ p(x) $ близко к нулю, а $ q(x) $ значительно ненулевое, влияние $ q $ игнорируется. Это может привести к ошибочным результатам, когда мы хотим измерить сходство между двумя равно важными распределениями.\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Давайте рассмотрим пример, иллюстрирующий концепции энтропии Шеннона и ожидаемой длины кода. Этот пример поможет понять, как вычисляется энтропия и как она связана с эффективностью кодирования.\n",
    "\n",
    "1. **2 состояния погоды (солнечно и дождливо) с равной вероятностью 50%:** \n",
    "   - Сколько бит нужно для кодирования информации?\n",
    "\n",
    "2. **8 состояний погоды с равной вероятностью:** \n",
    "   - Сколько бит нужно для кодирования информации в этом случае?\n",
    "\n",
    "3. **2 состояния погоды, но не равновероятны (солнечно 75%, дождливо 25%):** \n",
    "   - $$ H(p) = -\\sum_{x} p(x) \\log p(x) = 0.811 $$\n",
    "   - Это меньше 1 бита, что отражает тот факт, что состояния погоды не равновероятны, и информации для их кодирования требуется меньше.\n",
    "   - Интерпретировать это можно как среднее количество информации, которую мы можем получить при получении экземпляра при заданом распределении $p(x)$\n",
    "\n",
    "\n",
    "4. **8 состояний погоды в солнечном регионе с разной вероятностью:**\n",
    "<img width=600 src=\"https://ramsane.github.io/_nuxt/image/3c1dfb.png\" />\n",
    "   \n",
    "    - Энтропия Шеннона: $ H(p) = -\\sum_{x} p(x) \\log p(x) = 2.23$ битов\n",
    "    - Средняя длина кода: $ H(p, q) = -\\sum_{x} p(x) \\log q(x) = 3$ битов, где $log q$ - длина кодировки\n",
    "    - Что это значит? Что в среднем мы отправляем 3 бита информации, но только 2.23 бита являются информативными\n",
    "    - Давайте попробуем другую кодировку\n",
    "<img width=600 src=\"https://ramsane.github.io/_nuxt/image/6e9876.png\" />\n",
    "\n",
    "    - Средняя длина кода $H(p, q) = 2.42$ битов\n",
    "    - То есть мы теперь отправляем в среднем меньше битов 2.42 вместо 3, а получаем то же количество информации 2.23\n",
    "\n",
    "5. **Использование той же кодировки для дождливого региона:** \n",
    "<img width=600 src=\"https://ramsane.github.io/_nuxt/image/df606a.png\" />\n",
    "\n",
    "    - Если бы мы использовали ту же кодировку в регионе, где вероятности другие (например, дождливо - 35%)\n",
    "    - $H(p, q) = 4.58$\n",
    "    - Почти в два раза больше значения энтропии (2.23)\n",
    "    - Здесь же можно отметить, что $H(p, q) \\geq H(q)$, то есть длину кодировки мы можем оптимизировать только до самого значения энтропии\n",
    "    - $H(p, q)$ - назвают еще кросс энтропия\n",
    "\n",
    "6. **Кросс-энтропия (p - распределение солнечного региона, q - распределение дождливого):** \n",
    "   - Кросс-энтропия между двумя распределениями $ p $ и $ q $ измеряет среднюю \"длину\" кода, который оптимизирован для распределения $ q $, но используется для кодирования данных из распределения $ p $. Это показывает, насколько эффективно мы можем представить данные одного распределения, используя код, оптимизированный для другого.\n",
    "\n",
    "7. **KL-дивергенция и ее выражение через энтропию:**\n",
    "   - KL-дивергенция между $ p $ и $ q $ представляет собой разницу между кросс-энтропией и энтропией $ p $. Это мера того, насколько информация, оптимизированная для $ q $, \"неэффективна\" при использовании для представления данных из $ p $. Если $ p $ и $ q $ совпадают, KL-дивергенция равна нулю, указывая на полную эффективность кодирования.\n",
    "   - $ D_{KL} (p||q) = H(p, q) - H(p)$\n",
    "  \n",
    "\n",
    "\n",
    "#### Вывод KL-дивергенции\n",
    "1. **Энтропия Шеннона:** Это основная концепция, на которой строится KL-дивергенция. Энтропия Шеннона для вероятностного распределения $ p(x) $ определяется как средняя величина \"неопределённости\" или \"информации\" в распределении:\n",
    "\n",
    "$$ H(p) = -\\sum_{x} p(x) \\log p(x) $$\n",
    "\n",
    "2. **Ожидаемая длина кода:** Представьте, что вы кодируете события из распределения $ p(x) $, используя некоторый код, оптимизированный для другого распределения $ q(x) $. Средняя длина кода для событий из $ p(x) $ будет:\n",
    "\n",
    "   $$  H(p, q) = -\\sum_{x} p(x) \\log q(x) $$\n",
    "\n",
    "3. **KL-дивергенция как измерение \"неэффективности\":** KL-дивергенция измеряет, насколько неэффективен код, оптимизированный для $ q(x) $, при кодировании событий из $ p(x) $. Это разница между ожидаемой длиной кода (при использовании $ q(x) $) и энтропией $ p(x) $:\n",
    "\n",
    "   $$ D_{KL}(p \\parallel q) = \\left( -\\sum_{x} p(x) \\log q(x) \\right) - \\left( -\\sum_{x} p(x) \\log p(x) \\right) $$\n",
    "   $$ = \\sum_{x} p(x) \\log \\frac{p(x)}{q(x)} $$\n",
    "\n",
    "   Это выражение показывает разницу в \"количестве информации\" между двумя распределениями.\n",
    "\n",
    "4. **Интерпретация:** KL-дивергенция равна нулю, если $ p(x) $ и $ q(x) $ идентичны (то есть, код оптимален). Если распределения различаются, KL-дивергенция увеличивается, указывая на увеличение \"неэффективности\" или \"излишка\" в кодировании событий из $ p(x) $ с использованием кода для $ q(x) $.\n",
    "\n",
    "Эта формула считается асимметричной, так как $ D_{KL}(p \\parallel q) $ не обязательно равно $ D_{KL}(q \\parallel p) $. Это означает, что \"расстояние\" от $ p $ до $ q $ не то же самое, что и от $ q $ до $ p $.\n",
    "\n",
    "\n",
    "\n",
    "2. **Дженсен-Шеннона дивергенция (JS-дивергенция)** - это другая мера сходства между двумя вероятностными распределениями, ограниченная интервалом [0, 1]. JS-дивергенция симметрична и более гладкая:\n",
    "\n",
    "   $$ D_{JS}(p \\parallel q) = \\frac{1}{2} D_{KL}(p \\parallel \\frac{p + q}{2}) + \\frac{1}{2} D_{KL}(q \\parallel \\frac{p + q}{2}) $$\n",
    "\n",
    "   Некоторые исследователи считают, что одной из причин успеха GAN является замена функции потерь с асимметричной KL-дивергенции в традиционном подходе максимального правдоподобия на симметричную JS-дивергенцию. Более подробно мы обсудим этот вопрос в следующем разделе.\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2017-08-20-gan/KL_JS_divergence.png' />\n",
    "    <figcaption>Даны два гауссовских распределения: $ p $ с математическим ожиданием 0 и стандартным отклонением 1 и $ q $ с математическим ожиданием 1 и стандартным отклонением 1. Среднее этих двух распределений обозначается как $ m = \\frac{p + q}{2} $. Дивергенция Кульбака-Лейблера $ D_{KL} $ является асимметричной, в то время как дивергенция Дженсена-Шеннона $ D_{JS} $ симметрична.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f2b0c-ce88-46a5-9552-eb6a49105382",
   "metadata": {},
   "source": [
    "### Глава 3: Генеративно-Состязательная Сеть (GAN)\n",
    "\n",
    "**Генеративно-состязательная сеть (GAN)** состоит из двух моделей:\n",
    "\n",
    "1. **Дискриминатор (D)** оценивает вероятность того, что данный образец поступил из реального набора данных. Он выполняет функцию критика и оптимизирован для различения поддельных образцов от настоящих.\n",
    "\n",
    "2. **Генератор (G)** создает синтетические образцы на основе переменной шума $ z $ (переменная $ z $ вносит потенциальное разнообразие в результаты). Генератор обучается воспроизводить распределение реальных данных так, чтобы его генерируемые образцы были максимально реалистичными, или другими словами, чтобы обмануть дискриминатор и заставить его давать высокую вероятность.\n",
    "\n",
    "Эти две модели соревнуются друг с другом в процессе обучения: генератор $ G $ старается обмануть дискриминатор, в то время как дискриминатор $ D $ старается не быть обманутым. Эта интересная игра с нулевой суммой между двумя моделями мотивирует обе стороны улучшать свои функциональные возможности.\n",
    "\n",
    "В контексте GAN используются следующие обозначения:\n",
    "\n",
    "- $ p_z $ - распределение данных над входным шумом $ z $.\n",
    "- $ p_g $ - распределение генератора над данными $ x $.\n",
    "- $ p_r $ - распределение реальных образцов над $ x $.\n",
    "\n",
    "    - С одной стороны, мы стремимся убедиться, что дискриминатор $ D $ предсказывает реальные данные верно, максимизируя $ \\mathbb{E}_{x \\sim p_r}[log D(x)] $. \n",
    "    - В то же время, учитывая сгенерированные данные с помощью генератора $ G(z) $, $ z \\sim p_z $, ожидается, что дискриминатор выдаст вероятность $ D(G(z)) $, близкую к нулю, максимизируя $ \\mathbb{E}_{z \\sim p_z}[log(1 - D(G(z)))] $.\n",
    "\n",
    "    - С другой стороны, генератор обучается увеличивать шансы на то, что $ D $ выдаст высокую вероятность для поддельного примера, тем самым минимизируя $ \\mathbb{E}_{z \\sim p_z}[log(1 - D(G(z)))] $.\n",
    "\n",
    "Объединяя обе стороны вместе, $ D $ и $ G $ играют в минимаксную игру, в которой следует оптимизировать следующую функцию потерь:\n",
    "\n",
    "$$ \\min_{G} \\max_{D} L(D, G) = \\mathbb{E}_{x \\sim p_r}[log D(x)] + \\mathbb{E}_{z \\sim p_z}[log(1 - D(G(z)))] $$\n",
    "$$ = \\mathbb{E}_{x \\sim p_r}[log D(x)] + \\mathbb{E}_{x \\sim p_g}[log(1 - D(x))] $$\n",
    "\n",
    "где $ \\mathbb{E}_{x \\sim p_r}[log D(x)] $ не влияет на $ G $ во время  градиентного спуска.\n",
    "\n",
    "![](https://www.researchgate.net/publication/342379262/figure/fig12/AS:905488917090320@1592896789393/Overview-of-a-GAN-scheme-The-generator-G-produces-images-y-F-as-fake-samples-given-a.png)\n",
    "\n",
    "\n",
    "[Визуализация](https://poloclub.github.io/ganlab/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44827742-146b-41af-908d-ceb22d65b62b",
   "metadata": {},
   "source": [
    "### Глава 4: Проблематика в Генеративно-Состязательных Сетях\n",
    "\n",
    "Несмотря на значительные успехи в сфере генерации реалистичных изображений, процесс обучения генеративно-состязательных сетей (GAN) характеризуется определёнными сложностями: он медленный и подвержен нестабильности.\n",
    "\n",
    "#### 4.1 Проблема Достижения Равновесия Нэша\n",
    "\n",
    "В работах по теме обсуждается проблематика обучения GAN, основанного на градиентном спуске. Две модели - генератор и дискриминатор - обучаются одновременно с целью достижения равновесия Нэша в рамках несотрудничающей игры двух игроков. Тем не менее, каждая модель независимо обновляет свою функцию стоимости, не учитывая действия другого участника игры. Параллельное обновление градиентов обеих моделей не обеспечивает гарантии сходимости.\n",
    "\n",
    "Для лучшего понимания проблемы достижения равновесия Нэша рассмотрим простой пример. Предположим, один игрок контролирует переменную $ x $, стремясь минимизировать функцию $ f_1(x) = xy $, в то время как другой игрок изменяет $ y $, целясь минимизировать $ f_2(y) = -xy $.\n",
    "\n",
    "Учитывая, что $ \\frac{\\partial f_1}{\\partial x} = y $ и $ \\frac{\\partial f_2}{\\partial y} = -x $, обновление переменных $ x $ и $ y $ происходит одновременно в каждой итерации с использованием шага обучения $ \\eta $. В случае, когда $ x $ и $ y $ имеют различные знаки, каждое последующее обновление градиента вызывает значительные колебания, что приводит к усилению нестабильности со временем, как показано на рисунке.\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2017-08-20-gan/nash_equilibrium.png' />\n",
    "\n",
    "#### 4.2 Проблема размерности\n",
    "\n",
    "- **Многообразие:** Топологическое пространство, локально аналогичное евклидову пространству в окрестности каждой точки. Когда это пространство имеет размерность $ n $, многообразие называется $ n $-мерным.\n",
    "\n",
    "Распределение $p_r$ и $p_g$ лежат на низкоразмерном многообразии. \n",
    "\n",
    "Многие реальные наборы данных, представляемые $ p_r $, имеют искусственно высокие размерности. Они сконцентрированы на многообразиях более низкой размерности, что является основополагающим предположением для обучения на многообразиях. \n",
    "\n",
    "Например, для изображений, при фиксированной теме или объекте, изображения подчиняются определённым ограничениям, например, собака должна иметь два уха и хвост, а небоскреб - прямое и высокое строение. Эти ограничения предотвращают возможность получения изображений с высокоразмерной свободой формы.\n",
    "\n",
    "$ p_g $, аналогично, лежит на низкоразмерных многообразиях. Когда генератор создаёт изображения большего размера, распределение цветов по пикселям определяется небольшим вектором случайных чисел, что ограничивает заполнение высокоразмерного пространства.\n",
    "\n",
    "Поскольку и $ p_g $, и $ p_r $ располагаются на низкоразмерных многообразиях, они практически всегда будут непересекающимися. В таких условиях всегда можно найти идеальный дискриминатор, который с 100% точностью разделяет реальные и поддельные образцы.\n",
    "\n",
    "<img width=500 src='https://cdn.journals.aps.org/journals/PRX/key_images/10.1103/PhysRevX.10.041044.png' />\n",
    "\n",
    "#### 4.3 Исчезающий Градиент\n",
    "\n",
    "В случае совершенного дискриминатора, мы получаем \n",
    "- $ D(x) = 1 $ для всех $ x \\in p_r $\n",
    "- $ D(x) = 0 $ для всех $ x \\in p_g $. \n",
    "\n",
    "В результате функция потерь $ L $ стремится к нулю, и отсутствует градиент для обновления потерь в процессе обучения. Рисунок  демонстрирует эксперимент, в котором с улучшением дискриминатора градиент быстро уменьшается.\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2017-08-20-gan/GAN_vanishing_gradient.png' />\n",
    "\n",
    "Таким образом, обучение GAN сталкивается с дилеммой:\n",
    "\n",
    "- Если дискриминатор работает неэффективно, генератор не получает точную обратную связь, и функция потерь не отражает реальность.\n",
    "- Если дискриминатор эффективен, градиент функции потерь стремится к нулю, что замедляет процесс обучения или даже приводит к его застою.\n",
    "\n",
    "#### 4.4 Коллапс Мод (Mode Collapse)\n",
    "\n",
    "В ходе обучения может возникнуть ситуация, когда генератор начинает постоянно производить одни и те же выходные данные. Это явление, известное как коллапс мод, представляет собой распространенную проблему в обучении GAN. Несмотря на то, что генератор может успешно обмануть соответствующий дискриминатор, он не способен адекватно представить сложное распределение реальных данных и застревает в пространстве с крайне низким разнообразием.\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2017-08-20-gan/mode_collapse.png' />\n",
    "\n",
    "#### 4.5 Отсутствие Адекватной Метрики Оценки\n",
    "\n",
    "Генеративно-состязательные сети изначально не обладают эффективной функцией оценки, способной информировать о прогрессе обучения. Отсутствие надежной метрики оценки сравнимо с работой в условиях неопределенности: нет четких индикаторов для определения момента завершения обучения или для сравнения производительности нескольких моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29888a77-db58-4130-841c-335058a7fc0f",
   "metadata": {},
   "source": [
    "[Объяснение VAE](https://lilianweng.github.io/posts/2018-08-12-vae/)\n",
    "\n",
    "\n",
    "## **Автокодировщики (AutoEncoders)**\n",
    "\n",
    "Автокодировщики представляют собой семейство моделей нейронных сетей, целью которых является изучение сжатых скрытых переменных высокоразмерных данных.\n",
    "\n",
    "**Основные Обозначения**\n",
    "\n",
    "| Символ | Значение |\n",
    "| --- | --- |\n",
    "| $\\mathcal{D}$ | Набор данных, $\\mathcal{D} = \\{ \\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, ..., \\mathbf{x}^{(n)} \\}$, содержит $n$ образцов данных; $\\vert\\mathcal{D}\\vert = n$. |\n",
    "| $\\mathbf{x}^{(i)}$ | Каждая точка данных является вектором из $d$ измерений, $\\mathbf{x}^{(i)} = \\left[ x_1^{(i)}, x_2^{(i)}, ..., x_d^{(i)} \\right] $ | Один образец данных из набора данных, $\\mathbf{x} \\in \\mathcal{D}$. |\n",
    "| $\\mathbf{x}'$ | Реконструированная версия $\\mathbf{x}$. |\n",
    "| $\\tilde{\\mathbf{x}}$ | Искаженная версия $\\mathbf{x}$. |\n",
    "| $\\mathbf{z}$ | Сжатый вектор, полученный в узком промежуточном слое (bottleneck). |\n",
    "| $a_j^{(l)}$ | Функция активации для $j$-го нейрона в $l$-м скрытом слое. |\n",
    "| $g_{\\phi}(\\cdot)$ | Функция кодирования, параметризированная $\\phi$. |\n",
    "| $f_{\\theta}(\\cdot)$ | Функция декодирования, параметризированная $\\theta$. |\n",
    "| $q_{\\phi}(z \\vert x)$ | Оценочная апостериорная вероятностная функция, также известная как вероятностный кодировщик. |\n",
    "| $p_{\\theta}(x \\vert z)$ | Вероятность генерации истинного образца данных при данном скрытом коде, также известная как вероятностный декодировщик. |\n",
    "\n",
    "\n",
    "### **Автокодировщик**\n",
    "\n",
    "Автокодировщик - это нейронная сеть, разработанная для получения тождественной функции путем обучения без учителя. Цель такой сети воссоздать исходный ввод, сжимая данные в процессе, чтобы получить сжатое представление. Идея возникла в 1980-х годах и была популяризирована в основополагающей работе Хинтона и Салахутдинова в 2006 году.\n",
    "\n",
    "AE состоит из двух сетей:\n",
    "- **Сеть кодировщика**: Переводит исходные данные высокой размерности в скрытый вектор низкой размерности. Размер входа больше, чем размер выхода.\n",
    "- **Сеть декодировщика**: Сеть декодировщика восстанавливает данные из скрытого вектора, возможно, с увеличением размера выходных слоев.\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png' />\n",
    "\n",
    "Сеть кодировщика фактически выполняет сокращение размерности, подобно тому, как мы используем анализ главных компонентов (PCA) или факторизацию матриц. Кроме того, автокодировщик явно оптимизирован для восстановления данных из сжатого вектора.\n",
    "\n",
    "\n",
    "Модель содержит \n",
    "- функцию кодировщика $ g(\\cdot) $, параметризированную $ \\phi $\n",
    "- функцию декодировщика $ f(\\cdot) $, параметризированную $ \\theta $. \n",
    "\n",
    "Сжатый код низкой размерности, изученный для входа $ \\mathbf{x} $ в узком промежуточном слое, это $ \\mathbf{z} = g_{\\phi}(\\mathbf{x}) $, и реконструированный вход это $ \\mathbf{x}' = f_{\\theta}(g_{\\phi}(\\mathbf{x})) $.\n",
    "\n",
    "Параметры $ (\\theta, \\phi) $ обучаются совместно, чтобы вывести реконструированный образец данных, идентичный исходному входу, $ \\mathbf{x} \\approx f_{\\theta}(g_{\\phi}(\\mathbf{x})) $, или другими словами, для получения тождественной функции. В качестве метрики оценки схожести можно использовать например среднеквадратичную ошибку (MSE):\n",
    "\n",
    "$$ L_{AE}(\\theta, \\phi) = \\frac{1}{n} \\sum_{i=1}^{n} (\\mathbf{x}^{(i)} - f_{\\theta}(g_{\\phi}(\\mathbf{x}^{(i)})))^2 $$\n",
    "\n",
    "\n",
    "### **Шумоподавляющий Автокодировщик (Denoising Autoencoder)**\n",
    "\n",
    "Поскольку автокодировщик учит идентичную функцию, существует риск \"переобучения\", когда количество параметров сети превышает количество точек данных. \n",
    "\n",
    "Чтобы избежать переобучения и улучшить надежность, предложили Шумоподавляющий Автокодировщик как модификацию базового автокодировщика. \n",
    "\n",
    "Входные данные частично искажаются путем добавления шумов или маскировки некоторых значений входного вектора стохастическим образом, $\\tilde{\\mathbf{x}} \\sim \\mathcal{M}_\\mathcal{D}(\\tilde{\\mathbf{x}} \\vert \\mathbf{x})$. Затем модель обучается восстанавливать исходный ввод (не искаженный).\n",
    "\n",
    "Шум контролируется стохастическим отображением $\\mathcal{M}_\\mathcal{D}(\\tilde{\\mathbf{x}} \\vert \\mathbf{x})$ и не специфичен для какого-либо конкретного процесса зашумления изображения (например, маскирующего шума, гауссова шума, шума соль и перец и т. д.). \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\tilde{\\mathbf{x}}^{(i)} &\\sim \\mathcal{M}_\\mathcal{D}(\\tilde{\\mathbf{x}}^{(i)} \\vert \\mathbf{x}^{(i)})\\\\\n",
    "L_\\text{DAE}(\\theta, \\phi) &= \\frac{1}{n} \\sum_{i=1}^n (\\mathbf{x}^{(i)} - f_\\theta(g_\\phi(\\tilde{\\mathbf{x}}^{(i)})))^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2018-08-12-vae/denoising-autoencoder-architecture.png' />\n",
    "\n",
    "### **Разреженный Автокодировщик**\n",
    "\n",
    "Разреженный автокодировщик вводит ограничение \"разреженности\" на активацию скрытых нейронов, чтобы избежать переобучения и повысить надежность модели. Это заставляет модель активировать лишь небольшое число скрытых нейронов одновременно, или, другими словами, большую часть времени один скрытый нейрон должен быть неактивен.\n",
    "\n",
    "Напомним, что среди общепринятых функций активации - sigmoid, tanh, ReLU, Leaky ReLU и т.д. Нейрон считается активированным, когда его значение близко к 1, и неактивным, когда оно близко к 0.\n",
    "\n",
    "Предположим, что в $l$-м скрытом слое находится $s_l$ нейронов, и функция активации для $j$-го нейрона этого слоя обозначена как $a^{(l)}_j(.)$, $j=1, \\dots, s_l$. Доля активации этого нейрона $\\hat{\\rho}_j$ должна быть малым числом $\\rho$, известным как параметр разреженности; обычная настройка - $\\rho = 0.05$.\n",
    "\n",
    "$$ \\hat{\\rho}_j^{(l)} = \\frac{1}{n} \\sum_{i=1}^n [a_j^{(l)}(\\mathbf{x}^{(i)})] \\approx \\rho $$\n",
    "Это ограничение достигается путем добавления штрафного слагаемого в функцию потерь. $D_\\text{KL}$ измеряет разницу между двумя распределениями Бернулли, одно со средним значением $\\rho$, а другое - с $\\hat{\\rho}_j^{(l)}$. Гиперпараметр $\\beta$ контролирует степень штрафа, который мы хотим наложить на потери разреженности.\n",
    "\n",
    "$$ \\begin{aligned} L_\\text{SAE}(\\theta) &= L(\\theta) + \\beta \\sum_{l=1}^L \\sum_{j=1}^{s_l} D_\\text{KL}(\\rho \\| \\hat{\\rho}_j^{(l)}) \\\\ &= L(\\theta) + \\beta \\sum_{l=1}^L \\sum_{j=1}^{s_l} \\rho\\log\\frac{\\rho}{\\hat{\\rho}_j^{(l)}} + (1-\\rho)\\log\\frac{1-\\rho}{1-\\hat{\\rho}_j^{(l)}} \\end{aligned} $$\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2018-08-12-vae/kl-metric-sparse-autoencoder.png' />\n",
    "    <figcaption>Расхождение Кульбака-Лейблера между распределением Бернулли со средним значением $\\rho=0.25$ и распределением Бернулли со средним значением $0 \\leq \\hat{\\rho} \\leq 1$</figcaption>\n",
    "</figure>\n",
    "\n",
    "### k-Разреженный Автокодировщик\n",
    "\n",
    "В k-разреженном автокодировщике, разреженность обеспечивается путем сохранения только k наивысших активаций в узком промежуточном слое с линейной функцией активации. \n",
    "\n",
    "1. Сначала осуществляется прямое распространение через сеть кодировщика для получения сжатого вектора: $\\mathbf{z} = g(\\mathbf{x})$.\n",
    "2. Сортируются значения в векторе $\\mathbf{z}$. \n",
    "3. Сохраняются только k наибольших значений, остальные нейроны устанавливаются в ноль. Это также можно реализовать на слое ReLU с регулируемым порогом. \n",
    "4. Теперь у нас есть разреженный вектор: $\\mathbf{z}’ = \\text{Sparsify}(\\mathbf{z})$. \n",
    "\n",
    "Рассчитывается выход и потери от разреженного кода, $L = |\\mathbf{x} - f(\\mathbf{z}’)|_2^2$. И обратное распространение ошибки происходит только через k наиболее активированных скрытых нейронов!\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2018-08-12-vae/k-sparse-autoencoder.png' />\n",
    "    <figcaption>Фильтры k-разреженного автокодировщика для различных уровней разреженности k, обученные на данных MNIST с 1000 скрытыми нейронами</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "### **Контрактивный Автокодировщик (Contractive Autoencoder)**\n",
    "\n",
    "Аналогично разреженному автокодировщику, контрактивный автокодировщик стимулирует обученное представление оставаться в контрактивном пространстве для повышения его устойчивости. \n",
    "\n",
    "Он включает в функцию потерь штрафное слагаемое для наказания за чрезмерную чувствительность представления к входным данным, улучшая тем самым устойчивость к небольшим возмущениям вокруг точек обучающих данных. Чувствительность измеряется нормой Фробениуса матрицы якобиана активаций кодировщика относительно входа:\n",
    "\n",
    "$$ \\|\\mathbf{J}_f(\\mathbf{x})\\|^2_F = \\sum_{ij} \\left(\\frac{\\partial h_j(\\mathbf{x})}{\\partial x_i}\\right)^2 $$\n",
    "\n",
    "где $ h_j $ - это один из выходов сжатого вектора $ \\mathbf{z} = f(\\mathbf{x}) $.\n",
    "\n",
    "Этот штрафной член представляет собой сумму квадратов всех частных производных выученного кодирования относительно размерностей входа. Авторы утверждали, что, как показала практика, этот штраф помогает формировать представление, соответствующее низкоразмерному нелинейному многообразию, оставаясь более инвариантным к большинству направлений, ортогональным многообразию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6cf31-e369-4bbb-8ff1-bfaf0e853a17",
   "metadata": {},
   "source": [
    "### **Вариационный Автокодировщик (VAE)**\n",
    "\n",
    "Вместо отображения входа в фиксированный вектор, мы стремимся отобразить его в распределение. Обозначим это распределение как $ p_\\theta $, параметризированное $ \\theta $. Взаимосвязь между входными данными $ \\mathbf{x} $ и вектором скрытого кодирования $ \\mathbf{z} $ может быть полностью определена:\n",
    "\n",
    "- Априорное распределение $ p_\\theta(\\mathbf{z}) $\n",
    "- Функция правдоподобия $ p_\\theta(\\mathbf{x} | \\mathbf{z}) $\n",
    "- Апостериорное распределение $ p_\\theta(\\mathbf{z} | \\mathbf{x}) $\n",
    "\n",
    "Допустим мы знаем параметр $ \\theta^* $ для этого распределения. Чтобы сгенерировать пример, который похож на точку из данных $ \\mathbf{x}^{(i)} $, мы проведем следующие действия:\n",
    "\n",
    "1. Сначала выберем $ \\mathbf{z}^{(i)} $ из априорного распределения $ p_{\\theta^*}(\\mathbf{z}) $.\n",
    "2. Затем значение $ \\mathbf{x}^{(i)} $ генерируется из условного распределения $ p_{\\theta^*}(\\mathbf{x} | \\mathbf{z} = \\mathbf{z}^{(i)}) $.\n",
    "\n",
    "Оптимальным параметром $ \\theta^* $ называется тот, который максимизирует вероятность генерации примеров, схожих с реальными данными:\n",
    "\n",
    "$$ \\theta^* = \\arg\\max_\\theta \\prod_{i=1}^n p_\\theta(\\mathbf{x}^{(i)}) $$\n",
    "\n",
    "Преобразуем в логарифмические вероятности, чтобы поменять произведение на сумму:\n",
    "\n",
    "$$ \\theta^* = \\arg\\max_\\theta \\sum_{i=1}^n \\log p_\\theta(\\mathbf{x}^{(i)}) $$\n",
    "\n",
    "Теперь давайте раскроем $ p_\\theta(\\mathbf{x}^{(i)})$, используя вектор кодирования $\\mathbf{z}$:\n",
    "\n",
    "$$ p_\\theta(\\mathbf{x}^{(i)}) = \\int p_\\theta(\\mathbf{x}^{(i)} | \\mathbf{z}) p_\\theta(\\mathbf{z}) d\\mathbf{z} $$\n",
    "\n",
    "$ p_\\theta(\\mathbf{x}^{(i)}) $ не так просто вычислить таким образом, поскольку очень затратно проверить все возможные значения $ \\mathbf{z} $ и сложить их. \n",
    "\n",
    "Чтобы сузить пространство значений, введем новую функцию $ q_\\phi(\\mathbf{z} | \\mathbf{x}) $, параметризированную $ \\phi $, которая апроксимирует какой вектор $z$ вероятен при данном входе $ \\mathbf{x} $\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png' />\n",
    "    <figcaption>Графическая модель, задействованная в вариационном автокодировщике. Сплошные линии обозначают генеративное распределение $ p_\\theta(.) $, а пунктирные линии обозначают распределение $ q_\\phi (\\mathbf{z} | \\mathbf{x}) $ для приближения трудно поддающегося вычислению апостериорного распределения $ p_\\theta (\\mathbf{z} | \\mathbf{x}) $.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "Теперь структура очень похожа на автокодировщик:\n",
    "\n",
    "- Условная вероятность $ p_\\theta(\\mathbf{x} | \\mathbf{z}) $ определяет генеративную модель, аналогичную декодировщику $ f_\\theta(\\mathbf{x} | \\mathbf{z}) $, введенному выше. $ p_\\theta(\\mathbf{x} | \\mathbf{z}) $ также известна как вероятностный декодировщик.\n",
    "- Функция приближения $ q_\\phi(\\mathbf{z} | \\mathbf{x}) $ является вероятностным кодировщиком, играющим аналогичную роль, как $ g_\\phi(\\mathbf{z} | \\mathbf{x}) $ выше.\n",
    "\n",
    "\n",
    "### **Функция потерь: ELBO**\n",
    "\n",
    "Оценочное апостериорное распределение $ q_\\phi(\\mathbf{z}|\\mathbf{x}) $ должно быть очень близко к реальному $ p_\\theta(\\mathbf{z}|\\mathbf{x}) $. Мы можем использовать KL-дивергенцию для количественной оценки расстояния между этими двумя распределениями. $ D_{KL}(X|Y) $ измеряет, сколько информации теряется, если распределение Y используется для представления X.\n",
    "\n",
    "В нашем случае мы хотим минимизировать $ D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) | p_\\theta(\\mathbf{z}|\\mathbf{x})) $ относительно $ \\phi $.\n",
    "\n",
    "Но почему мы используем $ D_{KL}(q_\\phi | p_\\theta) $ (обратное KL) вместо $ D_{KL}(p_\\theta | q_\\phi) $ (прямое KL)?\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2018-08-12-vae/forward_vs_reversed_KL.png' />\n",
    "    <figcaption>Прямое и обратное расхождение Кульбака-Лейблера предъявляют различные требования к соответствию двух распределений.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Прямое расхождение Кульбака-Лейблера: $ D_{KL}(P|Q) = \\mathbb{E}_{z\\sim P(z)} \\log\\frac{P(z)}{Q(z)} $; нам нужно убедиться, что Q(z)>0, где P(z)>0. Оптимизированное вариационное распределение $ q(z) $ должно полностью покрывать $ p(z) $.\n",
    "\n",
    "Обратное расхождение Кульбака-Лейблера: $ D_{KL}(Q|P) = \\mathbb{E}_{z\\sim Q(z)} \\log\\frac{Q(z)}{P(z)} $; минимизация обратного расхождения Кульбака-Лейблера сжимает $ Q(z) $ под $ P(z) $.\n",
    "\n",
    "Теперь распишем уравнение:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}|\\mathbf{x})) & \\\\\n",
    "&= \\int q_\\phi(\\mathbf{z} | \\mathbf{x}) \\log\\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})}{p_\\theta(\\mathbf{z} | \\mathbf{x})} d\\mathbf{z} & \\\\\n",
    "&= \\int q_\\phi(\\mathbf{z} | \\mathbf{x}) \\log\\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})p_\\theta(\\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} d\\mathbf{z} & ; \\text{Так как } p(z | x) = \\frac{p(z, x)}{p(x)} \\\\\n",
    "&= \\int q_\\phi(\\mathbf{z} | \\mathbf{x}) \\left( \\log p_\\theta(\\mathbf{x}) + \\log\\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} \\right) d\\mathbf{z} & \\\\\n",
    "&= \\log p_\\theta(\\mathbf{x}) + \\int q_\\phi(\\mathbf{z} | \\mathbf{x})\\log\\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} d\\mathbf{z} & ; \\text{Так как } \\int q(z | x) dz = 1\\\\\n",
    "&= \\log p_\\theta(\\mathbf{x}) + \\int q_\\phi(\\mathbf{z} | \\mathbf{x})\\log\\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})}{p_\\theta(\\mathbf{x}|\\mathbf{z})p_\\theta(\\mathbf{z})} d\\mathbf{z} & ; \\text{Так как } p(z, x) = p(x | z) p(z) \\\\\n",
    "&= \\log p_\\theta(\\mathbf{x}) + \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} | \\mathbf{x})}[\\log \\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})}{p_\\theta(\\mathbf{z})} - \\log p_\\theta(\\mathbf{x} | \\mathbf{z})] &\\\\\n",
    "&= \\log p_\\theta(\\mathbf{x}) + D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}|\\mathbf{x})}\\log p_\\theta(\\mathbf{x}|\\mathbf{z}) &\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Таким образом, у нас есть:\n",
    "\n",
    "$$\n",
    "D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}|\\mathbf{x})) =\\log p_\\theta(\\mathbf{x}) + D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}|\\mathbf{x})}\\log p_\\theta(\\mathbf{x}|\\mathbf{z})\n",
    "$$\n",
    "\n",
    "$ D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}|\\mathbf{x})) $ — это расхождение Кульбака-Лейблера (KL-дивергенция) между приближенным апостериорным распределением $ q_\\phi(\\mathbf{z}|\\mathbf{x}) $, полученным кодировщиком, и истинным апостериорным распределением $ p_\\theta(\\mathbf{z}|\\mathbf{x}) $. Это расхождение измеряет, насколько информация теряется, если мы используем $ q_\\phi $ для приближения $ p_\\theta $. В идеальном случае, если $ q_\\phi $ и $ p_\\theta $ идентичны, KL-дивергенция будет равна нулю.\n",
    "\n",
    "$ \\log p_\\theta(\\mathbf{x}) $ — это логарифм совместной вероятности данных $ \\mathbf{x} $ под моделью с параметрами $ \\theta $. Мы не можем вычислить это напрямую, но мы можем максимизировать эту величину, оптимизируя остальные члены уравнения.\n",
    "\n",
    "$ D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) $ — KL-дивергенция между приближенным апостериорным распределением $ q_\\phi $ и априорным распределением $ p_\\theta(\\mathbf{z}) $. Этот член действует как регуляризатор, поощряя приближенное распределение быть близким к априорному распределению, которое обычно выбирается как стандартное нормальное распределение.\n",
    "\n",
    "$ - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}|\\mathbf{x})}\\log p_\\theta(\\mathbf{x}|\\mathbf{z}) $ — это отрицательное ожидание логарифмической вероятности данных $ \\mathbf{x} $, латентного представления $ \\mathbf{z} $. Этот член представляет собой реконструкционную потерю: он наказывает модель, если генерируемые декодировщиком данные $ \\mathbf{x} $ плохо соответствуют исходным данным.\n",
    "\n",
    "Объединяя все вместе, мы получаем следующее: минимизация функции потерь VAE эквивалентна максимизации ожидаемого логарифма вероятности данных и одновременной минимизации KL-дивергенции между приближенным апостериорным и априорным распределениями. Это позволяет модели эффективно генерировать новые данные, которые вероятны при данных параметрах модели, и при этом сохранять достоверное представление данных в латентном пространстве.\n",
    "\n",
    "\n",
    "\n",
    "Перепишем это уравнение:\n",
    "\n",
    "$$\n",
    "\\log p_\\theta(\\mathbf{x}) - D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}|\\mathbf{x})) = \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}|\\mathbf{x})}\\log p_\\theta(\\mathbf{x}|\\mathbf{z}) - D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}))\n",
    "$$\n",
    "\n",
    "Отрицание вышеописанного определяет нашу функцию потерь:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_{VAE}(\\theta, \\phi) &= -\\log p_\\theta(\\mathbf{x}) + D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}|\\mathbf{x}))\\\\\n",
    "&= -\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}|\\mathbf{x})}\\log p_\\theta(\\mathbf{x}|\\mathbf{z}) + D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) \\\\\n",
    "\\theta^{*}, \\phi^{*} &= \\arg\\min_{\\theta, \\phi} L_{VAE}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "В вариационных байесовских методах эта функция потерь известна как вариационная нижняя граница или нижняя граница доказательств. Часть \"нижняя граница\" в названии происходит от того, что расхождение Кульбака-Лейблера всегда неотрицательно, и таким образом $ -L_{VAE} $ является нижней границей $ \\log p_\\theta(\\mathbf{x}) $.\n",
    "\n",
    "$$\n",
    "-L_{VAE} = \\log p_\\theta(\\mathbf{x}) - D_{KL}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}|\\mathbf{x})) \\leq \\log p_\\theta(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Таким образом, минимизируя потери, мы максимизируем нижнюю границу вероятности генерации реальных выборок данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a079ba-77df-4766-a5c4-62886705c6b8",
   "metadata": {},
   "source": [
    "### **Трюк Репараметризации**\n",
    "\n",
    "Предполагается генерация выборки из $ \\mathbf{z} \\sim q_\\phi(\\mathbf{z}|\\mathbf{x}) $.\n",
    "\n",
    "Сама выборка является стохастическим процессом, и поэтому мы не совершить backpropagation. \n",
    "\n",
    "Для этого вводится трюк репараметризации: возможно выразить случайную переменную $ \\mathbf{z} $ как детерминированную переменную $ \\mathbf{z} = \\mathcal{T}_\\phi(\\mathbf{x}, \\boldsymbol{\\epsilon}) $, где $ \\boldsymbol{\\epsilon} $ - вспомогательная независимая случайная переменная, а функция преобразования $ \\mathcal{T}_\\phi $, параметризованная $ \\phi $, преобразует $ \\boldsymbol{\\epsilon} $ в $ \\mathbf{z} $.\n",
    "\n",
    "Например, распространённый вариант формы $ q_\\phi(\\mathbf{z}|\\mathbf{x}) $ - это многомерное гауссовское распределение с диагональной ковариационной структурой:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{z} &\\sim q_\\phi(\\mathbf{z}|\\mathbf{x}^{(i)}) = \\mathcal{N}(\\mathbf{z}; \\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\sigma}^{2(i)}\\boldsymbol{I}) & \\\\\n",
    "\\mathbf{z} &= \\boldsymbol{\\mu} + \\boldsymbol{\\sigma} \\odot \\boldsymbol{\\epsilon}, \\text{ где } \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\boldsymbol{I}) & ; \\text{Трюк репараметризации.}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "где $ \\odot $ обозначает покомпонентное произведение.\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2018-08-12-vae/reparameterization-trick.png' />\n",
    "    <figcaption>Иллюстрация того, как трюк репараметризации делает процесс выборки $ \\mathbf{z} $ обучаемым</figcaption>\n",
    "</figure>\n",
    "\n",
    "Трюк репараметризации работает и для других типов распределений, не только гауссовских. В случае многомерного гауссовского распределения мы делаем модель обучаемой, явно изучая среднее значение и дисперсию распределения, $ \\mu $ и $ \\sigma $, используя трюк репараметризации, в то время как стохастичность остается в случайной переменной $ \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\boldsymbol{I}) $.\n",
    "\n",
    "<figure>\n",
    "    <img width=600 src='https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png' />\n",
    "    <figcaption>Иллюстрация модели вариационного автокодировщика с предположением многомерного гауссовского распределения.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db73e39-a29e-4124-9184-071dfbf1b56e",
   "metadata": {},
   "source": [
    "### VQ-VAE (Vector Quantised-Variational AutoEncoder)\n",
    "\n",
    "\n",
    "Векторное квантование (VQ) — это метод, который отображает n-мерные векторы в конечное множество «кодовых» векторов из которых состовляется словарь.\n",
    "\n",
    "Процесс очень похож на алгоритм KNN. Оптимальный центроидный кодовый вектор, на который должен быть отображен образец, — это тот, который имеет минимальное евклидово расстояние.\n",
    "\n",
    "Пусть $ e \\in \\mathbb{R}^{K \\times D}, i = 1, ..., K $ \"кодовым словарем\", т.н. codebook в VQ-VAE, где $ K $ — это количество категорий скрытых переменных (слов в словаре), а $ D $ — размерность векторов.\n",
    "\n",
    "Выход кодировщика $ E(x) = z_e $ проходит через процедуру поиска ближайшего соседа, чтобы сопоставить его с одним из $ K $ векторов словаря, и затем этот сопоставленный кодовый вектор становится входом для декодера $ D(\\cdot) $:\n",
    "\n",
    "$$ z_q(x) = \\text{Quantize}(E(x)) = e_k, \\text{ где } k = \\arg\\min_i \\|E(x) - e_i\\|_2 $$\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2018-08-12-vae/VQ-VAE.png' />\n",
    "\n",
    "Обратите внимание, что дискретные скрытые переменные могут иметь различные формы в разных приложениях; например, 1D для речи, 2D для изображений и 3D для видео.\n",
    "\n",
    "Поскольку argmin() не дифференцируем на дискретном пространстве, градиенты $ \\nabla_z L $ от входа декодера $ z_q $ копируются на выход кодировщика $ z_e $. Помимо потерь реконструкции, VQ-VAE также оптимизирует:\n",
    "\n",
    "- VQ loss: L2 ошибка между codebook и выходами кодировщика.\n",
    "- Commitment loss: Мера, чтобы поощрять выход кодировщика оставаться близко к codebook и предотвратить его частое колебание от одного кодового вектора к другому.\n",
    "\n",
    "$$ L = \\|\\mathbf{x} - D(e_k)\\|_2^2 + \\|sg[E(\\mathbf{x})] - e_k\\|_2^2 + \\beta \\|E(\\mathbf{x}) - sg[e_k]\\|_2^2 $$\n",
    "\n",
    "где $ sg[\\cdot] $ — это оператор остановки градиента.\n",
    "\n",
    "Оператор остановки градиента позволяет \"копировать\" градиент от декодера к кодировщику, не воздействуя на процесс квантования, который преобразует непрерывные значения в дискретные.\n",
    "\n",
    "\n",
    "#### Обновление векторов в Codebook\n",
    "\n",
    "Векторы в кодовой книге обновляются через EMA (экспоненциальное скользящее среднее). Предположим, у нас есть $ n_i $ векторов выхода кодировщика, $ \\{\\mathbf{z}_{i,j}\\}^{n_i}_{j=1} $, которые квантуются до $ e_i $:\n",
    "\n",
    "$$ N^{(t)}_i = \\gamma N^{(t-1)}_i + (1 - \\gamma) n^{(t)}_i, \\quad \\mathbf{m}^{(t)}_i = \\gamma \\mathbf{m}^{(t-1)}_i + (1 - \\gamma) \\sum^{n^{(t)}_i}_{j=1} \\mathbf{z}_{i,j}, \\quad e^{(t)}_i = \\frac{\\mathbf{m}^{(t)}_i}{N^{(t)}_i} $$\n",
    "\n",
    "Давайте разберем этот процесс на части:\n",
    "\n",
    "Векторные квантовые автокодировщики (VQ-VAE) используют набор дискретных кодовых векторов, которые составляют \"кодовую книгу\". В процессе обучения VQ-VAE, входные данные кодируются в векторы $ \\mathbf{z} $, которые затем \"квантуются\" или сопоставляются с ближайшим вектором в кодовой книге. Это сопоставление происходит на основе минимизации евклидового расстояния между вектором $ \\mathbf{z} $ и векторами $ e_i $ в кодовой книге.\n",
    "\n",
    "- $ N^{(t)}_i $ — это количество векторов, которые были квантованы до вектора $ e_i $ на текущем шаге $ t $. Оно обновляется, сочетая предыдущее количество $ N^{(t-1)}_i $ с количеством новых квантований $ n^{(t)}_i $, взвешенных коэффициентом забывания $ \\gamma $.\n",
    "\n",
    "- $ \\mathbf{m}^{(t)}_i $ — это сумма всех векторов $ \\mathbf{z}_{i,j} $, которые были квантованы до $ e_i $, с учетом того же коэффициента забывания $ \\gamma $. Это обновление дает новое \"центроидное\" значение для вектора $ e_i $.\n",
    "\n",
    "- $ e^{(t)}_i $ — это обновленный вектор кодовой книги для $ e_i $, который вычисляется делением суммы $ \\mathbf{m}^{(t)}_i $ на общее количество квантований $ N^{(t)}_i $. Это дает новый центр кодового вектора, который отражает среднее положение всех векторов, квантованных до него.\n",
    "\n",
    "Все эти шаги вместе создают процесс, в котором векторы кодовой книги могут адаптироваться к данным, проходящим через модель, но делают это плавно, чтобы избежать резких изменений, которые могли бы нарушить устойчивость процесса обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400668d9-9782-493b-88ed-5a5b7e306dfb",
   "metadata": {},
   "source": [
    "## Diffusion Models\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/1*w_IfecnkATlrTlDMASAwBg.png)\n",
    "\n",
    "### Что такое модели диффузии?\n",
    "\n",
    "Модели диффузии — это класс генеративных моделей глубокого обучения, которые генерируют данные путем постепенного преобразования шума в структурированные образцы. Они используют стохастический процесс, который моделирует распределение данных путем выполнения серии шагов, в каждом из которых в данные вносится или удаляется шум.\n",
    "\n",
    "### Процесс прямой диффузии\n",
    "\n",
    "<img width=500 src='https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png' />\n",
    "\n",
    "Возьмем изображение из реального распределения данных $ X_0 \\sim q(X) $. Определим прямой диффузионный процесс, в котором мы добавляем небольшое количество гауссового шума к образцу за $ T $ шагов, производя последовательность шумных образцов $ X_1, ..., X_T $. Размеры шагов контролируются \"планировщиком\" дисперсии (variance schedule) $\\{ \\beta_t \\in (0,1) \\}^T_{t=1}$:\n",
    "\n",
    "$$ q(X_t|X_{t-1}) = N(X_t; \\sqrt{1 - \\beta_t}X_{t-1}, \\beta_tI), \\quad q(X_{1:T}|X_0) = \\prod^T_{t=1} q(X_t|X_{t-1}) $$\n",
    "\n",
    "Наше изображение $ X_0 $ постепенно теряет свои отличительные особенности по мере увеличения шага $ t $. В конечном итоге, когда $ T \\rightarrow \\infty $, $ X_T $ эквивалентен изотропному гауссовому распределению\n",
    "\n",
    "### Reparametrization trick\n",
    "\n",
    "Одним из привлекательных свойств вышеописанного процесса является то, что мы можем полуичить $ X_t $ в любой произвольный момент времени $ t $, используя трюк репараметризации. \n",
    "\n",
    "Пусть $ \\alpha_t = 1 - \\beta_t $ и $ \\tilde{\\alpha}_t = \\prod_{i=1}^t \\alpha_i $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& X_t = \\sqrt{\\alpha_t}X_{t-1} + \\sqrt{1 - \\alpha_t}\\epsilon_{t-1} &; \\text{где }  \\epsilon_{t-1}, \\epsilon_{t-2} \\sim  N(0, I) \\\\\n",
    "&= \\sqrt{\\alpha_t\\alpha_{t-1}}X_{t-2} + \\sqrt{1 - \\alpha_t\\alpha_{t-1}}\\tilde{\\epsilon}_{t-2} &; \\text{где } \\tilde{\\epsilon_{t-2}} \\text{ две Гауссианы*}\\\\\n",
    "&= ... \\\\\n",
    "&= \\sqrt{\\tilde{\\alpha}_t}X_0 + \\sqrt{1 - \\tilde{\\alpha}_t}\\epsilon \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$ X_t = \\sqrt{\\tilde{\\alpha}_t}X_0 + \\sqrt{1 - \\tilde{\\alpha}_t}\\epsilon $$\n",
    "\n",
    "(*) Помните, что когда мы объединяем два гауссова шума $ N(0, \\sigma_1^2 I) $ и $ N(0, \\sigma_2^2 I) $, новое распределение $ N(0, (\\sigma_1^2 + \\sigma_2^2)I) $. \n",
    "\n",
    "Здесь объединенное стандартное отклонение равно $ \\sqrt{(1 - \\alpha_t) + \\alpha_t(1 - \\alpha_{t-1})} = \\sqrt{1 - \\tilde{\\alpha}_t} $.\n",
    "\n",
    "Обычно мы можем позволить себе более крупные шаги обновления, когда образец становится более шумным, поэтому $ \\beta_1 < \\beta_2 < \\ldots < \\beta_T $ и, следовательно, $ \\delta_1 > \\ldots > \\delta_T $.\n",
    "\n",
    "### Обратный процесс диффузии\n",
    "\n",
    "Если нам удастся инвертировать указанный выше процесс и произвести выборку из распределения $ q(X_{t-1}|X_t) $, то мы сможем восстановить исходный образец из гауссовского шума, где $ X_T $ распределено нормально с параметрами $ N(0, I) $. Заметим, что при условии достаточной малости $ \\beta_t $, распределение $ q(X_{t-1}|X_t) $ также будет гауссовским. К сожалению, прямая оценка $ q(X_{t-1}|X_t) $ является непростой задачей, так как требует использования полного датасета, и, следовательно, возникает необходимость в обучении модели $ p_\\theta $ для приближения данных условных вероятностей в рамках процесса обратного диффузного переноса.\n",
    "\n",
    "$$ p_\\theta(X_{0:T}) = p(X_T) \\prod_{t=1}^T p_\\theta(X_{t-1}|X_t) $$\n",
    "$$ p_\\theta(X_{t-1}|X_t) = \\mathcal{N}(X_{t-1}; \\mu_\\theta(X_{t}, t), \\Sigma_\\theta(X_{t}, t)) $$\n",
    "\n",
    "где $ p_\\theta(X_{0:T}) $ обозначает совместное распределение всех состояний от начального времени до конечного в обратном времени, $ p(X_T) $ — априорное распределение конечного состояния шума, и произведение условных вероятностей $ p_\\theta(X_{t-1}|X_t) $ представляет последовательность шагов обратного диффузного переноса, каждый из которых моделируется нормальным распределением с параметрами, определяемыми функцией $ \\mu_\\theta $ для математического ожидания и функцией $ \\Sigma_\\theta $ для ковариационной матрицы, обе из которых зависят от текущего состояния $ X_t $ и времени $ t $.\n",
    "\n",
    "![](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/diffusion-example.png)\n",
    "\n",
    "\n",
    "[Более подробно про диффузионные модели](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9a13c-9953-48eb-84cd-749921554feb",
   "metadata": {},
   "source": [
    "#### Latent diffusion model\n",
    "\n",
    "![](https://theaisummer.com/static/ecb7a31540b18a8cbd18eedb446b468e/ee604/diffusion-models.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
